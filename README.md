# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #5 выполнил:
- Дубских Семён Николаевич
- РИ210950
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | * | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Интеграция экономической системы в проект Unity и обучение ML-Agent.

## Задание 1
### Измените параметры файла .yaml-агента и определить какие параметры и как влияют на обучение модели.

* Параметры по умолчанию. График `Cumulative Reward` возрастает монотонно верх, в виде логарифмической функции:

![до изменений](https://user-images.githubusercontent.com/45539357/204099825-6908e57d-9b0d-40d1-94d1-55b1a182c1c0.png)

* Параметр `learning_rate = 1.0e-5` соответствуют начальной скорости обучения для градиентного спуска. 
График сначала экспоненциально возрастает, дальше убывает. 
Другими словами вознаграждение за обучение достигло пика и начало опускаться:

![learning_rate1e-5](https://user-images.githubusercontent.com/45539357/204099751-c8118901-6325-435c-84cd-d609d21b308e.png)

* Параметр `beta = 1.0e-4` соответствует силе энтропийной регуляризации, которая делает политику «более случайной».
Обучение вознаграждалось за константу на каждом шаге, график прямой, стабильные обновления:

![beta1e-4](https://user-images.githubusercontent.com/45539357/204105291-b4bcebbd-e012-4df6-95f6-5cac838af533.png)

* Параметр `epsilon = 0.3` влияет на то, насколько быстро политика может развиваться во время обучения. График растёт вверх линейно, но медленно

![epsilon0 3](https://user-images.githubusercontent.com/45539357/204105720-3fdfae0f-246f-4b3e-b501-5dd29dfb2260.png)

* Параметр `lambd = 0.9` используется при расчете обобщенной оценки преимущества (GAE). График похож на параболу с ветвями вниз, обучение не стабильное:

![lambd0 9](https://user-images.githubusercontent.com/45539357/204106905-2dcdfe5d-9665-4023-bd45-9292a26c21c4.png)

* Параметр `num_epoch = 10` - количество проходов через буфер опыта при выполнении оптимизации градиентного спуска. Логарифмический график функции, не стабильные обновления:

![num_epoch10](https://user-images.githubusercontent.com/45539357/204107436-3b92e54e-0c7a-4747-9c9e-eb61a995d28b.png)

## Задание 2
### Построить графики зависимости количества эпох от ошибки обучения. Указать от чего зависит необходимое количество эпох обучения.

## Выводы

В ходе лабораторной работы я ознакомился с алгоритмом работы перцептрона. Реализовал несколько перцептронов, выполняющих вышеизложенные операции.
Построил графики завимостей количества эпох от ошибки обучения. А также сделал визуальную модель работы перцептрона, демонстрирующую возможное применение перцептрона.

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
